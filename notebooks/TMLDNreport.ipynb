{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3470c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -q calplot\n",
    "%pip install -q plotly\n",
    "\n",
    "subjectid=\"MIND006\"\n",
    "\n",
    "#PT UID\n",
    "part = 'U1918167344'\n",
    "#grab this as the intake info from REDCAP\n",
    "\n",
    "#Start date in MM/DD/YYYY\n",
    "start = '10/1/2024'\n",
    "# Make start date the day eligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01717f74-2001-4fb8-b121-c1c33d925a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pytz\n",
    "import calplot\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Set creds\n",
    "\n",
    "\n",
    "os.environ['LAMP_ACCESS_KEY'] = os.getenv('LAMPACCESSKEY')\n",
    "os.environ['LAMP_SECRET_KEY'] = os.getenv('LAMPSERVERKEY')\n",
    "os.environ['LAMP_SERVER_ADDRESS'] = 'api.lamp.digital'\n",
    "\n",
    "# Define REDCap API details\n",
    "api_url = \"https://redcap.ucdenver.edu/api/\"\n",
    "api_token = os.getenv('REDCAPAPI')\n",
    "\n",
    "\n",
    "#clinic_ids=pd.read_csv('pt_start_dates.csv')\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind, pearsonr\n",
    "\n",
    "import LAMP\n",
    "LAMP.connect()\n",
    "\n",
    "import cortex\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from datetime import datetime, timezone\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "logging.basicConfig(level=3)\n",
    "logging.getLogger('matplotlib').disabled = True\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "logging.getLogger('matplotlib.pyplot').disabled = True\n",
    "logging.getLogger('shapely.geos').disabled = True\n",
    "logging.getLogger('numexpr.utils').disabled = True\n",
    "logging.getLogger('feature_types:_wrapper2').disabled = True\n",
    "\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "MS_IN_DAY = 24 * 3600 * 1000\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2cd256-bac5-4b6d-a00e-f9640bad386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for Cortex\n",
    "\n",
    "run_sleep=True\n",
    "# default end date is now\n",
    "end_date = cortex.now()\n",
    "\n",
    "\n",
    "def timestamp(dt):\n",
    "    local = pytz.timezone(\"America/New_York\")\n",
    "    date = datetime.strptime(dt, '%m/%d/%Y')\n",
    "    local_dt = local.localize(date, is_dst=None)\n",
    "    utc_dt = local_dt.astimezone(pytz.utc)\n",
    "    utc_dt.replace(tzinfo=timezone.utc).timestamp() * 1000\n",
    "    return int(utc_dt.replace(tzinfo=timezone.utc).timestamp() * 1000)\n",
    "start_date = timestamp(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4924fe79-9625-4995-91ec-7ffbff9ab4ea",
   "metadata": {},
   "source": [
    "# Digital Clinic Patient Handout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc87b5b-6439-4c9f-8e8c-b28fff6cf165",
   "metadata": {},
   "source": [
    "This document presents the data that was collected during your time in the mindLAMP Study.  Feel free to reach out to the study team (digitalclinic@cuanschutz.edu) with any questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to fetch data from REDCap\n",
    "def fetch_redcap_data(record_id, event, fields):\n",
    "    payload = {\n",
    "        'token': api_token,\n",
    "        'content': 'record',\n",
    "        'format': 'json',\n",
    "        'records[0]': record_id,\n",
    "        'events[0]': event,\n",
    "        'type': 'flat',\n",
    "        'rawOrLabel': 'label'\n",
    "    }\n",
    "    \n",
    "    # Add multiple fields to the payload\n",
    "    for i, field in enumerate(fields):\n",
    "        payload[f'fields[{i}]'] = field\n",
    "    \n",
    "    response = requests.post(api_url, data=payload)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Fetch the gender, age, and race fields for record in intake_arm_2\n",
    "record_id = subjectid\n",
    "event = \"intake_arm_2\"\n",
    "fields = [\"gender\", \"age\", \"race\"]\n",
    "\n",
    "data = fetch_redcap_data(record_id, event, fields)\n",
    "\n",
    "# Extract and directly use the fetched data for age, gender, and race\n",
    "if data:\n",
    "    subject = f'Participant: {subjectid}'\n",
    "    age = f'Age: {data[0].get(\"age\", \"N/A\")}'\n",
    "    gender = f'Gender: {data[0].get(\"gender\", \"N/A\")}'\n",
    "    race = f'Race: {data[0].get(\"race\", \"N/A\")}'\n",
    "    \n",
    "    # Display the information with font size 4\n",
    "    display(Markdown(f'<font size=\"4\"><strong>{subject}<br/>{age}<br/>{gender}<br/>{race}</strong></font>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b2aea9-2449-44ff-8095-975f00d48d80",
   "metadata": {},
   "source": [
    "### Baseline Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac497daf-8d68-4560-b9ec-513e840a78dd",
   "metadata": {},
   "source": [
    "Throughout your time in the study, you will complete three surveys: an Intake survey during your first session with your Digital Navigator, an Interim survey after your third meeting with your clinician, and a Completion survey at the end of your last appointment. \n",
    "\n",
    "The graph below displays your responses to survey questions measuring anxiety, depression, and dysfunction (dysfunction represents how difficult it is to manage your day-to-day life and responsibilities). You can toggle over the survey category on the right to view all your survey responses together, or to only view your results from one of the surveys (just the Intake, for example). Clicking on the points on the graph shows your numerical score and what it is out of. Higher scores indicate having more symptoms of depression, anxiety, and/or dysfunction.\n",
    "\n",
    "We hope this graph will help you see what areas you have made progress in during your time in the study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d13037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The functions below will grab REDCap data to be used in graphs focused on weekly surveys\n",
    "\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np  # Import numpy for NaN\n",
    "\n",
    "# Function to fetch REDCap scores with events and fields\n",
    "def fetch_redcap_scores(record_id, events, fields):\n",
    "    payload = {\n",
    "        'token': api_token,\n",
    "        'content': 'record',\n",
    "        'format': 'json',\n",
    "        'records[0]': record_id,\n",
    "        'type': 'flat'\n",
    "    }\n",
    "    \n",
    "    # Add the events to the payload\n",
    "    for i, event in enumerate(events):\n",
    "        payload[f'events[{i}]'] = event\n",
    "    \n",
    "    # Add the fields to the payload\n",
    "    for i, field in enumerate(fields):\n",
    "        payload[f'fields[{i}]'] = field\n",
    "\n",
    "    response = requests.post(api_url, data=payload)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "# List of events\n",
    "events = [\n",
    "    \"pretx_arm_2\", \"visit_1_arm_2\", \"visit_2_arm_2\",\n",
    "    \"visit_3_arm_2\", \"visit_4_arm_2\", \"visit_5_arm_2\", \"visit_6_arm_2\"\n",
    "]\n",
    "\n",
    "# Helper function to process data\n",
    "def process_data(data, score_field, date_field, event_list, survey_name):\n",
    "    scores = []\n",
    "    event_counter = 0  # Initialize counter for events\n",
    "    for record in data:\n",
    "        if score_field in record and date_field in record:  # Ensure both fields exist\n",
    "            score = record[score_field]\n",
    "            event = event_list[event_counter] if event_counter < len(event_list) else \"Unknown Event\"\n",
    "            \n",
    "            # Handle the date parsing carefully\n",
    "            date_str = record.get(date_field, None)\n",
    "            date = np.nan  # Initialize with NaN\n",
    "            \n",
    "            if date_str:\n",
    "                try:\n",
    "                    date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "                except ValueError:\n",
    "                    date = np.nan\n",
    "            \n",
    "            if score == '':\n",
    "                score = np.nan\n",
    "\n",
    "            scores.append({'Event': event, 'Score': score, 'Date': date, 'Survey': survey_name})\n",
    "            event_counter += 1\n",
    "\n",
    "    return scores\n",
    "\n",
    "record_id = subjectid\n",
    "\n",
    "# Fetch PHQ-9 data\n",
    "phq9_data = fetch_redcap_scores(record_id, events, [\"phq9_score\", \"phq9_date\"])\n",
    "phq9_scores = process_data(phq9_data, \"phq9_score\", \"phq9_date\", events, \"Weekly PHQ-9 Survey\")\n",
    "\n",
    "# Handle intake_arm_2 for PHQ-9 separately\n",
    "intake_phq9_data = fetch_redcap_scores(record_id, [\"intake_arm_2\"], [\"eligibility_phq_score\", \"eligibility_date\"])\n",
    "if intake_phq9_data:\n",
    "    for record in intake_phq9_data:\n",
    "        eligibility_date_str = record.get(\"eligibility_date\", None)\n",
    "        eligibility_date = np.nan\n",
    "\n",
    "        if eligibility_date_str:\n",
    "            try:\n",
    "                eligibility_date = datetime.strptime(eligibility_date_str, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                eligibility_date = np.nan\n",
    "\n",
    "        phq_score = record.get(\"eligibility_phq_score\", np.nan)\n",
    "        if phq_score == '':\n",
    "            phq_score = np.nan\n",
    "\n",
    "        phq9_scores.append({'Event': 'intake_arm_2', 'Score': phq_score, 'Date': eligibility_date, 'Survey': 'Weekly PHQ-9 Survey'})\n",
    "\n",
    "# Fetch and process GAD-7 data\n",
    "gad7_data = fetch_redcap_scores(record_id, events, [\"gad7_score\", \"gad7_date\"])\n",
    "gad7_scores = process_data(gad7_data, \"gad7_score\", \"gad7_date\", events, \"Weekly GAD-7 Survey\")\n",
    "\n",
    "# Handle intake_arm_2 for GAD-7 separately\n",
    "intake_gad7_data = fetch_redcap_scores(record_id, [\"intake_arm_2\"], [\"eligibility_gad_score\", \"eligibility_date\"])\n",
    "if intake_gad7_data:\n",
    "    for record in intake_gad7_data:\n",
    "        eligibility_date_str = record.get(\"eligibility_date\", None)\n",
    "        eligibility_date = np.nan\n",
    "\n",
    "        if eligibility_date_str:\n",
    "            try:\n",
    "                eligibility_date = datetime.strptime(eligibility_date_str, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                eligibility_date = np.nan\n",
    "\n",
    "        gad_score = record.get(\"eligibility_gad_score\", np.nan)\n",
    "        if gad_score == '':\n",
    "            gad_score = np.nan\n",
    "\n",
    "        gad7_scores.append({'Event': 'intake_arm_2', 'Score': gad_score, 'Date': eligibility_date, 'Survey': 'Weekly GAD-7 Survey'})\n",
    "\n",
    "\n",
    "# Fetch Sleep Survey data\n",
    "sleep_data = fetch_redcap_scores(record_id, events, [\"sleep_score\", \"sleep_date\"])\n",
    "sleep_scores = process_data(sleep_data, \"sleep_score\", \"sleep_date\", events, \"Weekly Sleep Survey\")\n",
    "\n",
    "# Handle intake_arm_2 for Sleep Survey separately\n",
    "intake_sleep_data = fetch_redcap_scores(record_id, [\"intake_arm_2\"], [\"sleep_score\", \"sleep_date\"])\n",
    "if intake_sleep_data:\n",
    "    for record in intake_sleep_data:\n",
    "        eligibility_date_str = record.get(\"sleep_date\", None)\n",
    "        eligibility_date = np.nan\n",
    "\n",
    "        if eligibility_date_str:\n",
    "            try:\n",
    "                eligibility_date = datetime.strptime(eligibility_date_str, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                eligibility_date = np.nan\n",
    "\n",
    "        sleep_score = record.get(\"sleep_score\", np.nan)\n",
    "        if sleep_score == '':\n",
    "            sleep_score = np.nan\n",
    "\n",
    "        sleep_scores.append({'Event': 'intake_arm_2', 'Score': sleep_score, 'Date': eligibility_date, 'Survey': 'Weekly Sleep Survey'})\n",
    "\n",
    "\n",
    "\n",
    "# Fetch and process SDS data\n",
    "sds_data = fetch_redcap_scores(record_id, events, [\"sds_score\", \"sds_date\"])\n",
    "sds_scores = process_data(sds_data, \"sds_score\", \"sds_date\", events, \"Weekly SDS Survey\")\n",
    "\n",
    "# Handle intake_arm_2 for SDS separately\n",
    "intake_sds_data = fetch_redcap_scores(record_id, [\"intake_arm_2\"], [\"sds_score\", \"sds_date\"])\n",
    "if intake_sds_data:\n",
    "    for record in intake_sds_data:\n",
    "        eligibility_date_str = record.get(\"sds_date\", None)\n",
    "        eligibility_date = np.nan\n",
    "\n",
    "        if eligibility_date_str:\n",
    "            try:\n",
    "                eligibility_date = datetime.strptime(eligibility_date_str, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                eligibility_date = np.nan\n",
    "\n",
    "        sds_score = record.get(\"sds_score\", np.nan)\n",
    "        if sds_score == '':\n",
    "            sds_score = np.nan\n",
    "\n",
    "        sds_scores.append({'Event': 'intake_arm_2', 'Score': sds_score, 'Date': eligibility_date, 'Survey': 'Weekly SDS Survey'})\n",
    "\n",
    "\n",
    "\n",
    "# Fetch and process ESA data\n",
    "esa_data = fetch_redcap_scores(record_id, events, [\"esa_score\", \"esa_date\"])\n",
    "esa_scores = process_data(esa_data, \"esa_score\", \"esa_date\", events, \"Weekly ESA Survey\")\n",
    "\n",
    "# Handle intake_arm_2 for ESA separately\n",
    "intake_esa_data = fetch_redcap_scores(record_id, [\"intake_arm_2\"], [\"esa_score\", \"esa_date\"])\n",
    "if intake_esa_data:\n",
    "    for record in intake_esa_data:\n",
    "        eligibility_date_str = record.get(\"esa_date\", None)\n",
    "        eligibility_date = np.nan\n",
    "\n",
    "        if eligibility_date_str:\n",
    "            try:\n",
    "                eligibility_date = datetime.strptime(eligibility_date_str, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                eligibility_date = np.nan\n",
    "\n",
    "        esa_score = record.get(\"esa_score\", np.nan)\n",
    "        if esa_score == '':\n",
    "            esa_score = np.nan\n",
    "\n",
    "        esa_scores.append({'Event': 'intake_arm_2', 'Score': esa_score, 'Date': eligibility_date, 'Survey': 'Weekly ESA Survey'})\n",
    "\n",
    "\n",
    "# Fetch and process MSPSS data\n",
    "mspss_data = fetch_redcap_scores(record_id, events, [\"mspss_score\", \"mspss_date\"])\n",
    "mspss_scores = process_data(mspss_data, \"mspss_score\", \"mspss_date\", events, \"Weekly MSPSS Survey\")\n",
    "\n",
    "# Handle intake_arm_2 for MSPSS separately\n",
    "intake_mspss_data = fetch_redcap_scores(record_id, [\"intake_arm_2\"], [\"mspss_score\", \"mspss_date\"])\n",
    "if intake_mspss_data:\n",
    "    for record in intake_mspss_data:\n",
    "        eligibility_date_str = record.get(\"mspss_date\", None)\n",
    "        eligibility_date = np.nan\n",
    "\n",
    "        if eligibility_date_str:\n",
    "            try:\n",
    "                eligibility_date = datetime.strptime(eligibility_date_str, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                eligibility_date = np.nan\n",
    "\n",
    "        mspss_score = record.get(\"mspss_score\", np.nan)\n",
    "        if mspss_score == '':\n",
    "            mspss_score = np.nan\n",
    "\n",
    "        mspss_scores.append({'Event': 'intake_arm_2', 'Score': mspss_score, 'Date': eligibility_date, 'Survey': 'Weekly MSPSS Survey'})\n",
    "\n",
    "\n",
    "# Fetch and process Flourishing scale data\n",
    "fs_data = fetch_redcap_scores(record_id, events, [\"fs_score\", \"fs_date\"])\n",
    "fs_scores = process_data(fs_data, \"fs_score\", \"fs_date\", events, \"Weekly Flourishing Survey\")\n",
    "\n",
    "# Handle intake_arm_2 for Flourishing scale separately\n",
    "intake_fs_data = fetch_redcap_scores(record_id, [\"intake_arm_2\"], [\"fs_score\", \"fs_date\"])\n",
    "if intake_fs_data:\n",
    "    for record in intake_fs_data:\n",
    "        eligibility_date_str = record.get(\"fs_date\", None)\n",
    "        eligibility_date = np.nan\n",
    "\n",
    "        if eligibility_date_str:\n",
    "            try:\n",
    "                eligibility_date = datetime.strptime(eligibility_date_str, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                eligibility_date = np.nan\n",
    "\n",
    "        fs_score = record.get(\"fs_score\", np.nan)\n",
    "        if fs_score == '':\n",
    "            fs_score = np.nan\n",
    "\n",
    "        fs_scores.append({'Event': 'intake_arm_2', 'Score': fs_score, 'Date': eligibility_date, 'Survey': 'Weekly Flourishing Survey'})\n",
    "\n",
    "\n",
    "\n",
    "# Fetch and process PSE data\n",
    "pse_data = fetch_redcap_scores(record_id, events, [\"pse_score\", \"pse_date\"])\n",
    "pse_scores = process_data(pse_data, \"pse_score\", \"pse_date\", events, \"Weekly PSE Survey\")\n",
    "\n",
    "# Handle intake_arm_2 for PSE separately\n",
    "intake_pse_data = fetch_redcap_scores(record_id, [\"intake_arm_2\"], [\"pse_score\", \"pse_date\"])\n",
    "if intake_pse_data:\n",
    "    for record in intake_pse_data:\n",
    "        eligibility_date_str = record.get(\"pse_date\", None)\n",
    "        eligibility_date = np.nan\n",
    "\n",
    "        if eligibility_date_str:\n",
    "            try:\n",
    "                eligibility_date = datetime.strptime(eligibility_date_str, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                eligibility_date = np.nan\n",
    "\n",
    "        pse_score = record.get(\"pse_score\", np.nan)\n",
    "        if pse_score == '':\n",
    "            pse_score = np.nan\n",
    "\n",
    "        pse_scores.append({'Event': 'intake_arm_2', 'Score': pse_score, 'Date': eligibility_date, 'Survey': 'Weekly PSE Survey'})\n",
    "\n",
    "\n",
    "# Fetch and process DHLS data\n",
    "dhls_data = fetch_redcap_scores(record_id, events, [\"dhls_score\", \"dhls_date\"])\n",
    "dhls_scores = process_data(dhls_data, \"dhls_score\", \"dhls_date\", events, \"Weekly DHLS Survey\")\n",
    "\n",
    "# Handle intake_arm_2 for DHLS separately\n",
    "intake_dhls_data = fetch_redcap_scores(record_id, [\"intake_arm_2\"], [\"dhls_score\", \"dhls_date\"])\n",
    "if intake_dhls_data:\n",
    "    for record in intake_dhls_data:\n",
    "        eligibility_date_str = record.get(\"dhls_date\", None)\n",
    "        eligibility_date = np.nan\n",
    "\n",
    "        if eligibility_date_str:\n",
    "            try:\n",
    "                eligibility_date = datetime.strptime(eligibility_date_str, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                eligibility_date = np.nan\n",
    "\n",
    "        dhls_score = record.get(\"dhls_score\", np.nan)\n",
    "        if dhls_score == '':\n",
    "            dhls_score = np.nan\n",
    "\n",
    "        dhls_scores.append({'Event': 'intake_arm_2', 'Score': dhls_score, 'Date': eligibility_date, 'Survey': 'Weekly DHLS Survey'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combine all scores\n",
    "all_scores = phq9_scores + gad7_scores + sleep_scores + sds_scores + esa_scores + mspss_scores + fs_scores + pse_scores + dhls_scores\n",
    "\n",
    "# Convert to DataFrame\n",
    "weekly_df = pd.DataFrame(all_scores)\n",
    "\n",
    "# Format 'Date' column to match 'YYYY-MM-DD' format, handle NaT separately\n",
    "def format_date(x):\n",
    "    if pd.isna(x):  # Check for NaT\n",
    "        return np.nan  # Return NaN for NaT values\n",
    "    elif isinstance(x, datetime):  # Check if it's a valid datetime object\n",
    "        return x.strftime('%Y-%m-%d')\n",
    "    return np.nan  # For any other case, return NaN\n",
    "\n",
    "# Apply the formatting to the 'Date' column\n",
    "weekly_df['Date'] = weekly_df['Date'].apply(format_date)\n",
    "\n",
    "# Filter out rows where the 'Score' is NaN\n",
    "filtered_df = weekly_df[~weekly_df['Score'].isna()]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1491baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to safely extract a score for a given event and survey\n",
    "def get_score_for_event(df, event, survey_name):\n",
    "    # Filter the DataFrame for the given event and survey\n",
    "    filtered = df[(df['Event'] == event) & (df['Survey'] == survey_name)]\n",
    "    \n",
    "    # Check if the filtered DataFrame is empty and return NaN if no data exists\n",
    "    if filtered.empty or pd.isna(filtered['Score'].iloc[0]):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return filtered['Score'].iloc[0]\n",
    "\n",
    "# Extract the scores for each event\n",
    "intake_phq = get_score_for_event(filtered_df, 'intake_arm_2', 'Weekly PHQ-9 Survey')\n",
    "interim_phq = get_score_for_event(filtered_df, 'visit_3_arm_2', 'Weekly PHQ-9 Survey')\n",
    "final_phq = get_score_for_event(filtered_df, 'visit_6_arm_2', 'Weekly PHQ-9 Survey')\n",
    "\n",
    "intake_gad = get_score_for_event(filtered_df, 'intake_arm_2', 'Weekly GAD-7 Survey')\n",
    "interim_gad = get_score_for_event(filtered_df, 'visit_3_arm_2', 'Weekly GAD-7 Survey')\n",
    "final_gad = get_score_for_event(filtered_df, 'visit_6_arm_2', 'Weekly GAD-7 Survey')\n",
    "\n",
    "intake_sds = get_score_for_event(filtered_df, 'intake_arm_2', 'Weekly SDS Survey')\n",
    "interim_sds = get_score_for_event(filtered_df, 'visit_3_arm_2', 'Weekly SDS Survey')\n",
    "final_sds = get_score_for_event(filtered_df, 'visit_6_arm_2', 'Weekly SDS Survey')\n",
    "\n",
    "intake_esa = get_score_for_event(filtered_df, 'intake_arm_2', 'Weekly ESA Survey')\n",
    "interim_esa = get_score_for_event(filtered_df, 'visit_3_arm_2', 'Weekly ESA Survey')\n",
    "final_esa = get_score_for_event(filtered_df, 'visit_6_arm_2', 'Weekly ESA Survey')\n",
    "\n",
    "intake_mspss = get_score_for_event(filtered_df, 'intake_arm_2', 'Weekly MSPSS Survey')\n",
    "interim_mspss = get_score_for_event(filtered_df, 'visit_3_arm_2', 'Weekly MSPSS Survey')\n",
    "final_mspss = get_score_for_event(filtered_df, 'visit_6_arm_2', 'Weekly MSPSS Survey')\n",
    "\n",
    "intake_fs = get_score_for_event(filtered_df, 'intake_arm_2', 'Weekly Flourishing Survey')\n",
    "interim_fs = get_score_for_event(filtered_df, 'visit_3_arm_2', 'Weekly Flourishing Survey')\n",
    "final_fs = get_score_for_event(filtered_df, 'visit_6_arm_2', 'Weekly Flourishing Survey')\n",
    "\n",
    "intake_pse = get_score_for_event(filtered_df, 'intake_arm_2', 'Weekly PSE Survey')\n",
    "interim_pse = get_score_for_event(filtered_df, 'visit_3_arm_2', 'Weekly PSE Survey')\n",
    "final_pse = get_score_for_event(filtered_df, 'visit_6_arm_2', 'Weekly PSE Survey')\n",
    "\n",
    "intake_dhls = get_score_for_event(filtered_df, 'intake_arm_2', 'Weekly DHLS Survey')\n",
    "interim_dhls = get_score_for_event(filtered_df, 'visit_3_arm_2', 'Weekly DHLS Survey')\n",
    "final_dhls = get_score_for_event(filtered_df, 'visit_6_arm_2', 'Weekly DHLS Survey')\n",
    "\n",
    "\n",
    "\n",
    "# Print the values to verify\n",
    "print(\"Intake PHQ:\", intake_phq)\n",
    "print(\"Interim PHQ:\", interim_phq)\n",
    "print(\"Final PHQ:\", final_phq)\n",
    "\n",
    "print(\"Intake ESA:\", intake_esa)\n",
    "print(\"Interim ESA:\", interim_esa)\n",
    "print(\"Final ESA:\", final_esa)\n",
    "\n",
    "print(\"Intake MSPSS:\", intake_mspss)\n",
    "print(\"Interim MSPSS:\", interim_mspss)\n",
    "print(\"Final MSPSS:\", final_mspss)\n",
    "\n",
    "print(\"Intake FS:\", intake_fs)\n",
    "print(\"Interim FS:\", interim_fs)\n",
    "print(\"Final FS:\", final_fs)\n",
    "\n",
    "print(\"Intake PSE:\", intake_pse)\n",
    "print(\"Interim PSE:\", interim_pse)\n",
    "print(\"Final PSE:\", final_pse)\n",
    "\n",
    "print(\"Intake DHLS:\", intake_dhls)\n",
    "print(\"Interim DHLS:\", interim_dhls)\n",
    "print(\"Final DHLS:\", final_dhls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f6249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# Define the categories for the radar chart\n",
    "categories = ['Depression', 'Anxiety', 'Difficulty Functioning']\n",
    "\n",
    "# Convert inputs to numeric, treating invalid inputs as NaN\n",
    "intake_phq = pd.to_numeric(intake_phq, errors='coerce')\n",
    "intake_gad = pd.to_numeric(intake_gad, errors='coerce')\n",
    "intake_sds = pd.to_numeric(intake_sds, errors='coerce')\n",
    "\n",
    "interim_phq = pd.to_numeric(interim_phq, errors='coerce')\n",
    "interim_gad = pd.to_numeric(interim_gad, errors='coerce')\n",
    "interim_sds = pd.to_numeric(interim_sds, errors='coerce')\n",
    "\n",
    "final_phq = pd.to_numeric(final_phq, errors='coerce')\n",
    "final_gad = pd.to_numeric(final_gad, errors='coerce')\n",
    "final_sds = pd.to_numeric(final_sds, errors='coerce')\n",
    "\n",
    "# Initialize the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Check and add intake data if all intake values are available\n",
    "if pd.notna(intake_phq) and pd.notna(intake_gad) and pd.notna(intake_sds):\n",
    "    phq_scaled = intake_phq / 27\n",
    "    gad_scaled = intake_gad / 21\n",
    "    sds_scaled = intake_sds / 30\n",
    "\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=[phq_scaled, gad_scaled, sds_scaled],\n",
    "        theta=categories,\n",
    "        line_color='#F6222E',\n",
    "        fill='toself',\n",
    "        name='Intake',\n",
    "        text=[f'{intake_phq} out of 27', f'{intake_gad} out of 21', f'{intake_sds} out of 30'],\n",
    "        hovertemplate='Score: %{text}'\n",
    "    ))\n",
    "\n",
    "# Check and add interim data if all interim values are available\n",
    "if pd.notna(interim_phq) and pd.notna(interim_gad) and pd.notna(interim_sds):\n",
    "    phq_interim_scaled = interim_phq / 27\n",
    "    gad_interim_scaled = interim_gad / 21\n",
    "    sds_interim_scaled = interim_sds / 30\n",
    "\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=[phq_interim_scaled, gad_interim_scaled, sds_interim_scaled],\n",
    "        theta=categories,\n",
    "        line_color='#3366CC',\n",
    "        fill='toself',\n",
    "        name='Interim',\n",
    "        text=[f'{interim_phq} out of 27', f'{interim_gad} out of 21', f'{interim_sds} out of 30'],\n",
    "        hovertemplate='Score: %{text}'\n",
    "    ))\n",
    "\n",
    "# Check and add final data if all final values are available\n",
    "if pd.notna(final_phq) and pd.notna(final_gad) and pd.notna(final_sds):\n",
    "    phq_final_scaled = final_phq / 27\n",
    "    gad_final_scaled = final_gad / 21\n",
    "    sds_final_scaled = final_sds / 30\n",
    "\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=[phq_final_scaled, gad_final_scaled, sds_final_scaled],\n",
    "        theta=categories,\n",
    "        line_color='#2E8B57',\n",
    "        fill='toself',\n",
    "        name='Final',\n",
    "        text=[f'{final_phq} out of 27', f'{final_gad} out of 21', f'{final_sds} out of 30'],\n",
    "        hovertemplate='Score: %{text}'\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    polar=dict(radialaxis=dict(visible=False, range=[0, 1])),\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Display the radar chart if any data is available\n",
    "if fig.data:\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No valid data to display.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac89ed12-07ac-4b4f-8988-76277d51a2ce",
   "metadata": {},
   "source": [
    "The graph below displays your responses to survey questions measuring your self efficacy, motivation, digital literacy, emotional self awareness, and perceived social support. Like in the first graph, you can toggle over which survey you are seeing on the right, or you can click on the graph points to look at your numerical scores. Higher scores indicate greater feelings of motivation, self efficacy, self awareness, and social support, or a greater amount of digital literacy. \n",
    "\n",
    "The goal of this graph it so show what areas you have grown in during your time in the Digital Clinic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ad439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# Define the categories for the radar chart\n",
    "categories = ['Self Efficacy', 'Digital Literacy', 'Emotional Self Awareness', 'Perceived Social Support', 'Flourishing Scale']\n",
    "\n",
    "# Convert inputs to numeric, treating invalid inputs as NaN\n",
    "intake_pse = pd.to_numeric(intake_pse, errors='coerce')\n",
    "intake_dhls = pd.to_numeric(intake_dhls, errors='coerce')\n",
    "intake_esa = pd.to_numeric(intake_esa, errors='coerce')\n",
    "intake_mspss = pd.to_numeric(intake_mspss, errors='coerce')\n",
    "intake_fs = pd.to_numeric(intake_fs, errors='coerce')\n",
    "\n",
    "\n",
    "# Initialize the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Check and add intake data if all intake values are available\n",
    "if pd.notna(intake_pse) and pd.notna(intake_dhls) and pd.notna(intake_esa) and pd.notna(intake_mspss) and pd.notna(intake_fs):\n",
    "    pse_scaled = intake_pse / 40\n",
    "    dhls_scaled = intake_dhls / 12\n",
    "    esa_scaled = intake_esa / 5\n",
    "    mspss_scaled = intake_mspss / 84\n",
    "    fs_scaled = intake_fs / 56\n",
    "\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=[pse_scaled, dhls_scaled, esa_scaled, mspss_scaled, fs_scaled],\n",
    "        theta=categories,\n",
    "        line_color='#F6222E',\n",
    "        fill='toself',\n",
    "        name='Intake',\n",
    "        text=[f'{intake_pse} out of 40', f'{intake_dhls} out of 12', f'{intake_esa} out of 5', f'{intake_mspss} out of 84', f'{intake_fs} out of 56'],\n",
    "        hovertemplate='Score: %{text}'\n",
    "    ))\n",
    "\n",
    "\n",
    "interim_pse = pd.to_numeric(interim_pse, errors='coerce') \n",
    "interim_dhls = pd.to_numeric(interim_dhls, errors='coerce') \n",
    "interim_esa = pd.to_numeric(interim_esa, errors='coerce')  \n",
    "interim_mspss = pd.to_numeric(interim_mspss, errors='coerce')  \n",
    "interim_fs = pd.to_numeric(interim_fs, errors='coerce')  \n",
    "\n",
    "\n",
    "if pd.notna(interim_pse) and pd.notna(interim_dhls) and pd.notna(interim_esa) and pd.notna(interim_mspss) and pd.notna(interim_fs):\n",
    "    pse_interim_scaled = interim_pse / 40\n",
    "    dhls_interim_scaled = interim_dhls / 12\n",
    "    esa_interim_scaled = interim_esa / 5\n",
    "    mspss_interim_scaled = interim_mspss / 84\n",
    "    fs_interim_scaled = interim_fs / 56\n",
    "\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=[pse_interim_scaled, dhls_interim_scaled, esa_interim_scaled, mspss_interim_scaled, fs_interim_scaled],\n",
    "        theta=categories,\n",
    "        line_color='#3366CC',\n",
    "        fill='toself',\n",
    "        name='Interim',\n",
    "        text=[f'{interim_pse} out of 40', f'{interim_dhls} out of 12', f'{interim_esa} out of 5', f'{interim_mspss} out of 84', f'{interim_fs} out of 56'],\n",
    "        hovertemplate='Score: %{text}'\n",
    "    ))\n",
    "\n",
    "\n",
    "\n",
    "final_pse = pd.to_numeric(final_pse, errors='coerce')  \n",
    "final_dhls = pd.to_numeric(final_dhls, errors='coerce')  \n",
    "final_esa = pd.to_numeric(final_esa, errors='coerce')  \n",
    "final_mspss = pd.to_numeric(final_mspss, errors='coerce')  \n",
    "final_fs = pd.to_numeric(final_fs, errors='coerce')  \n",
    "\n",
    "if pd.notna(final_pse) and pd.notna(final_dhls) and pd.notna(final_esa) and pd.notna(final_mspss) and pd.notna(final_fs):\n",
    "    pse_final_scaled = final_pse / 40\n",
    "    dhls_final_scaled = final_dhls / 12\n",
    "    esa_final_scaled = final_esa / 5\n",
    "    mspss_final_scaled = final_mspss / 84\n",
    "    fs_final_scaled = final_fs / 56\n",
    "\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=[pse_final_scaled, dhls_final_scaled, esa_final_scaled, mspss_final_scaled, fs_final_scaled],\n",
    "        theta=categories,\n",
    "        line_color='#2E8B57',\n",
    "        fill='toself',\n",
    "        name='Final',\n",
    "        text=[f'{final_pse} out of 40', f'{final_dhls} out of 12', f'{final_esa} out of 5', f'{final_mspss} out of 84', f'{final_fs} out of 56'],\n",
    "        hovertemplate='Score: %{text}'\n",
    "    ))\n",
    "\n",
    "\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    polar=dict(radialaxis=dict(visible=False, range=[0, 1])),\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Display the radar chart if any data is available\n",
    "if fig.data:\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No valid data to display.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba76744-e2c6-43ac-9bba-d38e3e0ea0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_response(part_id):\n",
    "    '''This function returns participant responses to CBT exercises, Triggers,\n",
    "    and Patient Activation and Empowerment each week.'''\n",
    "\n",
    "    MS_IN_DAY = 86400000\n",
    "    one_week_ago = (cortex.now() - (7 * MS_IN_DAY))\n",
    "    activity_event_dict = LAMP.ActivityEvent.all_by_participant(part_id)['data']\n",
    "    cbt_list = []\n",
    "    triggers_list = []\n",
    "    pae_list = []\n",
    "    non_dep_events = []\n",
    "\n",
    "    try:\n",
    "        for event in activity_event_dict:\n",
    "            try:\n",
    "                event['activity'] = LAMP.Activity.view(event['activity'])['data'][0]['name']\n",
    "                non_dep_events.append(event)\n",
    "            except:\n",
    "                continue\n",
    "        for event in non_dep_events:\n",
    "            if (event['timestamp'] < cortex.now()) and (event['timestamp'] > one_week_ago):\n",
    "                if 'CBT' in event['activity']:\n",
    "                    cbt_list.append(event)\n",
    "                if 'Triggers' in event['activity']:\n",
    "                    triggers_list.append(event)\n",
    "                if 'Activation and Empowerment' in event['activity']:\n",
    "                    pae_list.append(event)\n",
    "                if 'Thinking' in event['activity']:\n",
    "                    cbt_list.append(event)\n",
    "        if len(cbt_list) == 0:\n",
    "            print(\"Patient did not complete any CBT exercises this week\")\n",
    "        else:\n",
    "            for exercise in cbt_list:\n",
    "                print(exercise['activity'])\n",
    "                print('\\033[1m' + str(datetime.fromtimestamp(exercise['timestamp']/1000).date()) + '\\033[0m')\n",
    "                print(\" \")\n",
    "                for question in exercise['temporal_slices']:\n",
    "                    print('\\033[1m' + question['item'] + '\\033[0m')\n",
    "                    print(question['value'])\n",
    "                    print(\" \")\n",
    "                print(\" \")\n",
    "                print(\" \")\n",
    "\n",
    "        if len(triggers_list) == 0:\n",
    "            print(\"Patient did not complete 'Triggers' module this week\")\n",
    "        else:\n",
    "            for exercise in triggers_list:\n",
    "                print(exercise['activity'])\n",
    "                print('\\033[1m' + str(datetime.fromtimestamp(exercise['timestamp']/1000).date()) + '\\033[0m')\n",
    "                print(\" \")\n",
    "                for question in exercise['temporal_slices']:\n",
    "                    print('\\033[1m' + question['item'] + '\\033[0m')\n",
    "                    print(question['value'])\n",
    "                print(\" \")\n",
    "                print(\" \")\n",
    "\n",
    "        if len(pae_list) == 0:\n",
    "            print(\"Patient did not complete 'Patient Activation and Empowerment' module this week\")\n",
    "        else:\n",
    "            for exercise in pae_list:\n",
    "                print(exercise['activity'])\n",
    "                print('\\033[1m' + str(datetime.fromtimestamp(exercise['timestamp']/1000).date()) + '\\033[0m')\n",
    "                print(\" \")\n",
    "                for question in exercise['temporal_slices']:\n",
    "                    print('\\033[1m' + question['item'] + '\\033[0m')\n",
    "                    print(question['value'])\n",
    "                print(\" \")\n",
    "                print(\" \")\n",
    "    except:\n",
    "        print('Oops - something has gone wrong. Check if your participant has any data')\n",
    "\n",
    "    return(None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17561b89-ca14-4694-8bcd-1c99bb9729b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_response(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45beeaf2-622c-4164-85c9-07b2032ac0f3",
   "metadata": {},
   "source": [
    "### Activity Calendar "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae07d58-e851-4626-94ed-26535afc146a",
   "metadata": {},
   "source": [
    "This graph shows the activities that you completed each day. Dates are along the x-axis, while the y-axis shows how many activities you completed that day, and the colors on the bars designate the activity names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e6314-61f3-4b52-9a10-39792af790ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cortex.visualizations.participant.active(part, attach_graphs=True, sample_length=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d57d0-9336-4674-8ce7-8804f344083f",
   "metadata": {},
   "source": [
    "### Weekly Surveys So Far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d58ef30-f09c-4542-83ec-3581f04106cf",
   "metadata": {},
   "source": [
    "During your time in the clinic, you completed weekly surveys measuring anxiety (GAD-7), depression (PHQ-9) levels, and sleep quality. The line graph shows your scores over your time in the clinic, with blue measuring anxiety, red measuring depression levels, and green measuring sleep quality. The goal of this graph is to measure your progress with your depression and anxiety symptoms throughout your time in the clinic. \n",
    "\n",
    "Higher scores designate higher values of depression and anxiety. Anxiety values are measured from 0 to 21, and depression values are measured from 0 to 27. Your sleep score ranges from 8 to 40, with a 40 representing poor sleep and an 8 representing good sleep. The lower the score, the better your sleep quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f221c-6c54-4818-8b4d-dfc9715d6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for pulling weekly surveys\n",
    "\n",
    "\n",
    "sleep_scoring_dict = {'category_list': ['Weekly Sleep Survey'],\n",
    "                    'questions': {\n",
    "                    'My sleep was restless.': {'category': 'Weekly Sleep Survey', 'scoring':'map1'},\n",
    "                    'I was satisfied with my sleep.': {'category': 'Weekly Sleep Survey', 'scoring':'map1'},\n",
    "                    'My sleep was refreshing.': {'category': 'Weekly Sleep Survey', 'scoring':'map1'},\n",
    "                    'I had difficulty falling asleep.': {'category': 'Weekly Sleep Survey', 'scoring':'map1'},\n",
    "                    'I had trouble staying asleep.':{'category': 'Weekly Sleep Survey', 'scoring':'map1'},\n",
    "                    'I had trouble sleeping.': {'category': 'Weekly Sleep Survey', 'scoring':'map1'},\n",
    "                    'I got enough sleep.': {'category': 'Weekly Sleep Survey', 'scoring':'map1'},\n",
    "                    'My sleep quality was...': {'category': 'Weekly Sleep Survey', 'scoring':'map1'},\n",
    "                    },\n",
    "                    'map1': {\n",
    "                        '1': 1,\n",
    "                        '2': 2,\n",
    "                        '3': 3,\n",
    "                        '4': 4,\n",
    "                        '5': 5\n",
    "                    },\n",
    "                   }\n",
    "\n",
    "sleep_dict = cortex.primary.survey_scores.survey_scores(id=part, start=start_date, end=end_date,scoring_dict=sleep_scoring_dict)\n",
    "score_list = []\n",
    "for survey in sleep_dict['data']:\n",
    "    score_list.append({'timestamp':datetime.fromtimestamp(survey['end']/1000).date(),'score':survey['score']})\n",
    "\n",
    "sleep = pd.DataFrame(score_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6abdb-c080-4a73-a788-d76ef2046963",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sleep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34769521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Create Depression DataFrame from PHQ-9 scores\n",
    "dep_df = weekly_df[weekly_df['Survey'] == \"Weekly PHQ-9 Survey\"].copy()\n",
    "dep_df['Score'] = pd.to_numeric(dep_df['Score'], errors='coerce')  # Ensure 'Score' is numeric\n",
    "\n",
    "# Create Anxiety DataFrame from GAD-7 scores\n",
    "anx_df = weekly_df[weekly_df['Survey'] == \"Weekly GAD-7 Survey\"].copy()\n",
    "anx_df['Score'] = pd.to_numeric(anx_df['Score'], errors='coerce')  # Ensure 'Score' is numeric\n",
    "\n",
    "# Create Sleep DataFrame from sleep scores\n",
    "sleep_df = weekly_df[weekly_df['Survey'] == \"Weekly Sleep Survey\"].copy()\n",
    "sleep_df['Score'] = pd.to_numeric(sleep_df['Score'], errors='coerce')  # Ensure 'Score' is numeric\n",
    "\n",
    "\n",
    "# Convert 'Date' columns to datetime for compatibility with plotting\n",
    "dep_df['Date'] = pd.to_datetime(dep_df['Date'], errors='coerce')\n",
    "anx_df['Date'] = pd.to_datetime(anx_df['Date'], errors='coerce')\n",
    "sleep_df['Date'] = pd.to_datetime(sleep_df['Date'], errors='coerce')\n",
    "\n",
    "dep_df = dep_df.sort_values(by='Date').reset_index(drop=True)\n",
    "anx_df = anx_df.sort_values(by='Date').reset_index(drop=True)\n",
    "sleep_df = sleep_df.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add Anxiety data trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=anx_df['Date'], \n",
    "    y=anx_df['Score'], \n",
    "    visible=True, \n",
    "    name='Weekly Anxiety Survey', \n",
    "    mode='lines+markers',\n",
    "))\n",
    "\n",
    "# Add Depression data trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dep_df['Date'], \n",
    "    y=dep_df['Score'], \n",
    "    visible=True, \n",
    "    name='Weekly Depression Survey', \n",
    "    mode='lines+markers',\n",
    "))\n",
    "\n",
    "# Add Sleep data trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=sleep_df['Date'], \n",
    "    y=sleep_df['Score'], \n",
    "    visible=True, \n",
    "    name='Weekly Sleep Survey', \n",
    "    mode='lines+markers',\n",
    "))\n",
    "\n",
    "\n",
    "# Update the layout for the figure\n",
    "fig.update_layout(\n",
    "    title='Weekly Survey Scores', \n",
    "    xaxis_title='Date', \n",
    "    yaxis_title='Score',\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        tickangle=45,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        range=[0, 30],  # Adjusted range to accommodate potential PHQ-9, GAD-7, and SDS scores\n",
    "    ),\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd93ccc-2bb4-4758-9fc1-4fe1493aac2c",
   "metadata": {},
   "source": [
    "#### Quick notes about interpreting correlations:\n",
    "- The numbers and colors correspond to the strength of the relationship. A correlation of -1 indicates a perfect negative relationship (as one variable increases the other variable decreases), and a correlation of 1 indicates a perfect positive relationship (both variables are increasing or decreasing). \n",
    "- A correlation of 0 means there is no linear relationship. However, just because a correlation is 0 does not necessarily mean there is no relationship there. There is always the possibility two variables have a nonlinear relationship.\n",
    "- Correlation does not equal causation. This graph cannot show that one variable causes a change in another variable, only how changes in variables are associated with each other.\n",
    "\n",
    "Potential example of interpreting this graph: Maybe you have a negative correlation between mood and steps. A negative correlation indicates that on days when your steps are higher, your mood is higher/better. Questions to think about: How does going on a walk make you feel? Do you usually feel better, worse, or about the same after you go on walks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904789ab-e3d1-4fd2-ac2a-250a84b7ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {'category_list': ['Daily Mood Survey', 'Daily Anxiety Survey', 'Daily Function Survey'],\n",
    "                    'questions': {\n",
    "                    'Overall, how would you rate your mood today?': {'category': 'Daily Mood Survey', 'scoring':'M_map'},\n",
    "                    'Overall, how would I rate my anxiety today?': {'category': 'Daily Anxiety Survey', 'scoring':'A_map'},\n",
    "                    'I am able to manage my day-to-day life': {'category': 'Daily Function Survey', 'scoring':'F_map'},\n",
    "                    },\n",
    "                    'A_map': {\n",
    "                        '10': 10,\n",
    "                        '9': 9,\n",
    "                        '8': 8,\n",
    "                        '7': 7,\n",
    "                        '6': 6, \n",
    "                        '5': 5, \n",
    "                        '4': 4, \n",
    "                        '3': 3,\n",
    "                        '2': 2,\n",
    "                        '1': 1,\n",
    "                        '0': 0,\n",
    "                    },\n",
    "                    'M_map': {\n",
    "                        '10': 0,\n",
    "                        '9': 1,\n",
    "                        '8': 2,\n",
    "                        '7': 3,\n",
    "                        '6': 4, \n",
    "                        '5': 5, \n",
    "                        '4': 6, \n",
    "                        '3': 7,\n",
    "                        '2': 8,\n",
    "                        '1': 9,\n",
    "                        '0': 10,\n",
    "                    },\n",
    "                    'F_map': {\n",
    "                        '4': 0,\n",
    "                        '3': 1,\n",
    "                        '2': 2,\n",
    "                        '1': 3,\n",
    "                        '0': 4}\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ba5d8-6979-4122-85a4-b490c54f0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling passive data\n",
    "try:\n",
    "    passive = cortex.run(part,\n",
    "                            ['screen_duration',\n",
    "                             # 'nearby_device_count', \n",
    "                             'entropy', 'data_quality', 'hometime', 'steps'],\n",
    "                            feature_params={'screen_duration': {}, 'entropy': {},\n",
    "                            'data_quality': {\"feature\":\"gps\", \"bin_size\":3600000}},\n",
    "                            start=start_date,\n",
    "                            end=end_date)\n",
    "except Exception as e:\n",
    "    passive = cortex.run(part,\n",
    "                            ['screen_duration', 'nearby_device_count','entropy', 'data_quality', 'hometime'],\n",
    "                            feature_params={'screen_duration': {}, 'entropy': {},\n",
    "                            'data_quality': {\"feature\":\"gps\", \"bin_size\":3600000}},\n",
    "                            start=start_date,\n",
    "                            end=end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7047660-1504-460a-9cad-2d1dbdcd4f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_df = pd.DataFrame()\n",
    "for key in passive:\n",
    "    if key != 'steps':\n",
    "        passive_df[key] = passive[key]['value']\n",
    "        passive_df['date'] = passive[key]['timestamp']\n",
    "    else:\n",
    "        if passive[key].empty:\n",
    "            continue\n",
    "        else:\n",
    "            step_df = passive[key]\n",
    "            # Convert 'timestamp' to datetime\n",
    "            step_df['timestamp'] = pd.to_datetime(step_df['timestamp'], errors='coerce')\n",
    "            # Filter for step count\n",
    "            step_df = step_df[step_df['type'] == 'step_count']\n",
    "            # Extract date from timestamp\n",
    "            step_df['date'] = step_df['timestamp'].dt.date\n",
    "            # Group by date and calculate max\n",
    "            step_df = step_df.groupby('date')['value'].max().reset_index()\n",
    "            # Assign steps to passive df\n",
    "            passive_df['steps'] = step_df['value']\n",
    "\n",
    "if 'steps' in passive_df:\n",
    "    passive_df = passive_df[['date', 'screen_duration', 'entropy', 'data_quality', 'hometime', 'steps']]\n",
    "else:\n",
    "    passive_df = passive_df[['date', 'screen_duration', 'entropy', 'data_quality', 'hometime']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f67426",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(passive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f8cb9-2c76-41d0-bc61-1a623575b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathering Sleep onset/offset for duration\n",
    "actevent = pd.DataFrame(LAMP.ActivityEvent.all_by_participant(part)[\"data\"])\n",
    "sleepevent = actevent[actevent['activity'] == 'b73q0szm06aekhd7w3sn']\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "\n",
    "# Function to convert sleep times to datetime\n",
    "def convert_sleep_time(time_str, date):\n",
    "    time = datetime.strptime(time_str, '%I:%M%p').time()\n",
    "    return datetime.combine(date, time)\n",
    "\n",
    "# Convert timestamp to datetime in EST\n",
    "sleepevent['timestamp'] = pd.to_datetime(sleepevent['timestamp'], unit='ms').dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\n",
    "\n",
    "sleepevent['date'] = sleepevent['timestamp'].dt.date\n",
    "\n",
    "# Calculate sleep duration\n",
    "sleep_durations = []\n",
    "for index, row in sleepevent.iterrows():\n",
    "    # Extract date part of the datetime\n",
    "    date = row['timestamp'].date()\n",
    "    \n",
    "    # Convert sleep onset and offset to datetime\n",
    "    sleep_onset = convert_sleep_time(sleepevent['temporal_slices'][index][3]['value'], date)\n",
    "    sleep_offset = convert_sleep_time(sleepevent['temporal_slices'][index][4]['value'], date)\n",
    "    \n",
    "    # Adjust for cases where sleep spans across midnight\n",
    "    if sleep_offset < sleep_onset:\n",
    "        sleep_offset += timedelta(days=1)\n",
    "    \n",
    "    # Calculate duration\n",
    "    duration = sleep_offset - sleep_onset\n",
    "    sleep_durations.append(duration.total_seconds() / 3600)  # Convert to hours\n",
    "\n",
    "# Add sleep duration to the dataframe\n",
    "sleepevent['sleep_duration_hours'] = sleep_durations\n",
    "\n",
    "\n",
    "sleepevent.drop(columns = {'temporal_slices', 'duration', 'static_data', 'activity', 'timestamp', '_parent'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d68b0-72ee-412c-b715-8bb5b477059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling dailies\n",
    "daily_dict_responses = cortex.primary.survey_scores.survey_scores(id=part,\n",
    "                                                        start=start_date,\n",
    "                                                        end=end_date,\n",
    "                                                        return_ind_ques=1,\n",
    "                                                        scoring_dict=score_dict)\n",
    "response_data = daily_dict_responses['data']\n",
    "function = []\n",
    "anxiety = []\n",
    "mood = []\n",
    "\n",
    "for item in response_data:\n",
    "    if item['question'] == \"Daily Function Survey\":\n",
    "        function.append({'score':item['score'], 'date':item['end']})\n",
    "    if item['question'] == \"Daily Anxiety Survey\":\n",
    "        anxiety.append({'score':item['score'], 'date':item['end']})\n",
    "    if item['question'] == \"Daily Mood Survey\":\n",
    "        mood.append({'score':item['score'], 'date':item['end']})\n",
    "\n",
    "\n",
    "for dictionary in function:\n",
    "    dictionary['date'] = datetime.fromtimestamp(dictionary['date']/1000).date()\n",
    "\n",
    "for dictionary in anxiety:\n",
    "    dictionary['date'] = datetime.fromtimestamp(dictionary['date']/1000).date()\n",
    "\n",
    "for dictionary in mood:\n",
    "    dictionary['date'] = datetime.fromtimestamp(dictionary['date']/1000).date()\n",
    "\n",
    "daily_df_function = pd.DataFrame(function)\n",
    "daily_df_anxiety = pd.DataFrame(anxiety)\n",
    "daily_df_mood = pd.DataFrame(mood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d33dc55-c601-41ff-9dd8-9141596b1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(daily_dict_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7e43f-fa6e-4150-ae1e-fc18a8831922",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_df['date'] = pd.to_datetime(passive_df['date'], unit='ms')\n",
    "\n",
    "passive_df['date'] = passive_df['date'].dt.tz_localize('UTC')\n",
    "\n",
    "passive_df['date'] = passive_df['date'].dt.tz_convert('US/Eastern')\n",
    "\n",
    "passive_df['date'] = passive_df['date'].apply(lambda x: x.date())\n",
    "\n",
    "if len(daily_df_function) > 0:\n",
    "    daily_df_function = daily_df_function.groupby('date')['score'].mean().reset_index()\n",
    "    daily_df_function = daily_df_function.rename(columns=({'score':'difficulty functioning'}))\n",
    "    passive_df = passive_df.merge(daily_df_function, on=['date'], how='left')\n",
    "else:\n",
    "    print(\"No completed Daily Functioning surveys found\")\n",
    "\n",
    "if len(daily_df_anxiety) > 0:\n",
    "    daily_df_anxiety = daily_df_anxiety.groupby('date')['score'].mean().reset_index()\n",
    "    daily_df_anxiety = daily_df_anxiety.rename(columns=({'score':'anxiety'}))\n",
    "    passive_df = passive_df.merge(daily_df_anxiety, on=['date'], how='left')\n",
    "else:\n",
    "    print(\"No completed Daily Anxiety surveys found\")\n",
    "\n",
    "if len(daily_df_mood) > 0:\n",
    "    daily_df_mood = daily_df_mood.groupby('date')['score'].mean().reset_index()\n",
    "    daily_df_mood = daily_df_mood.rename(columns=({'score':'depression'}))\n",
    "    passive_df = passive_df.merge(daily_df_mood, on=['date'], how='left')\n",
    "else:\n",
    "    print(\"No completed Daily Depression surveys found\")\n",
    "    \n",
    "if len(sleepevent) > 0:\n",
    "    sleepevent = sleepevent.groupby('date')['sleep_duration_hours'].mean().reset_index()\n",
    "    passive_df = passive_df.merge(sleepevent, on=['date'], how='left')\n",
    "else:\n",
    "    print(\"No completed Daily Sleep surveys found\")\n",
    "\n",
    "\n",
    "passive_df['screen_duration'] = passive_df['screen_duration'].replace(0, np.nan)\n",
    "passive_df['entropy'] = passive_df['entropy'].replace(0, np.nan)\n",
    "\n",
    "\n",
    "try:\n",
    "    sleep_df['date'] = sleep_df['timestamp'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    sleep_df = sleep_df[['date', 'hours']]\n",
    "    sleep_df.columns = ['date', 'sleep duration']\n",
    "    passive_df = pd.merge(passive_df, sleep_df, on=['date'])\n",
    "    passive_df['sleep duration'] = passive_df['sleep duration'].astype(float)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "passive_df['date'] = passive_df['date'].astype(object)\n",
    "cor_data = (passive_df.corr(min_periods=5).stack()\n",
    "          .reset_index()   \n",
    "          .rename(columns={0: 'correlation', 'level_0': 'variable', 'level_1': 'variable2'}))\n",
    "cor_data['correlation_label'] = cor_data['correlation'].map('{:.2f}'.format)  # Round to 2 decimal\n",
    "\n",
    "\n",
    "cor_data = cor_data[cor_data['correlation'] != 1.00]\n",
    "\n",
    "cor_data = cor_data[cor_data['correlation'] != -1.00]\n",
    "\n",
    "base = alt.Chart(cor_data).transform_filter(\n",
    "alt.datum.variable > alt.datum.variable2\n",
    ").encode(\n",
    "    x='variable2:O',\n",
    "    y='variable:O'    \n",
    ")\n",
    "\n",
    "text = base.mark_text().encode(\n",
    "    text='correlation_label',\n",
    "    color=alt.condition(\n",
    "        alt.datum.correlation > 0.5, \n",
    "        alt.value('white'),\n",
    "        alt.value('black')\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "cor_plot = base.mark_rect().encode(\n",
    "    color='correlation:Q'\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=200\n",
    ")\n",
    "cor_matrix = cor_plot + text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea68dc7-4d05-4936-8a6d-5855189dcf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfab605-09a2-4d09-8202-d5e071397162",
   "metadata": {},
   "source": [
    "### Daily Survey Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eef9f9-a43c-455a-87e5-3cf6f72b9770",
   "metadata": {},
   "source": [
    "### Daily Survey Scores and Passive Data Features (Nearby Devices, Hometime, Screentime, Entropy)\n",
    "\n",
    "The below graphs display passive data features collected from your smarphone with your scores on your daily surveys measuring anxiety, function, and mood. The scale for the passive data features is on the left y-axis, and the scale for the daily surveys is on the right y-axis side. The goal of these graphs is to help display patterns between your passive data features and routines with your mood, anxiety, and function levels. \n",
    "\n",
    "For example, you may see that for days on which you were on your phone screen more, your mood was typically higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c79cb-88a8-49ef-8e66-784565084c6a",
   "metadata": {},
   "source": [
    "* NOTE: Higher anxiety levels correspond with increased anxiety; 0 being no anxiety and 10 being the worst. Higher mood levels correspond with a better mood; 1 being the worst and 10 being the best. Higher function levels correspond with feeling like you are more able to manage day-to-day life on a scale of 0 to 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd54bd-560b-412a-a6a5-9025c12a2837",
   "metadata": {},
   "source": [
    "Entropy is a measure of how much a participant moves around to different locations. Higher entropy typically means that the participant's time is more evenly split between different locations, while low entropy means that a person spends the vast majority of their time at one location.\n",
    "\n",
    "Nearby devices is a measure of, if your phone is turned on and connected to bluetooth, how many devices around you are also turned on and connected to bluetooth. It can be used as a measure of sociability. For example, if you are spending a lot of time in spaces with lots of people, like a concert or a busy coffee shop, there will be more people and devices around you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f8167-2d88-4ed0-bc52-7cea8de87a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_df.rename(columns = {'difficulty functioning':'dysfunction'}, inplace = True)\n",
    "passive_df['screen_duration'] = passive_df['screen_duration']/3600000\n",
    "passive_df['hometime'] = passive_df['hometime']/3600000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec2ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(passive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6288b4-231a-4786-98af-a18915fcce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_visibility(option_position, total_options, traces_per_option):\n",
    "    return [True if i // traces_per_option == option_position else False for i in range(total_options * traces_per_option)]\n",
    "\n",
    "x = passive_df['date']\n",
    "\n",
    "# Handle missing 'sleep_duration_hours' column\n",
    "sleep_duration = passive_df['sleep_duration_hours'].fillna(np.nan).tolist() if 'sleep_duration_hours' in passive_df else [np.nan] * len(passive_df)\n",
    "\n",
    "# Handles missing dep, anx, fxn data in passive_df\n",
    "#dep_line = passive_df['depression'].fillna(np.nan).tolist() if 'depression' in passive_df else [np.nan] * len(passive_df)\n",
    "#anx_line = passive_df['anxiety'].fillna(np.nan).tolist() if 'anxiety' in passive_df else [np.nan] * len(passive_df)\n",
    "#fxn_line = passive_df['dysfunction'].fillna(np.nan).tolist() if 'dysfunction' in passive_df else [np.nan] * len(passive_df)\n",
    "\n",
    "dep_line = passive_df['depression'].fillna(np.nan).values  # Using `.values` to ensure its a proper numpy array\n",
    "anx_line = passive_df['anxiety'].fillna(np.nan).values\n",
    "fxn_line = passive_df['dysfunction'].fillna(np.nan).values\n",
    "\n",
    "\n",
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# OPTION 1 = Screentime\n",
    "fig.add_trace(go.Bar(x=x, y=passive_df['screen_duration'], visible=True, marker=dict(color='#CCE5FF'), name='Screentime'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=x, y=dep_line, mode='lines+markers', connectgaps=True, line=dict(width=2), visible=True, name='Depression'), secondary_y=True)\n",
    "fig.add_trace(go.Scatter(x=x, y=anx_line, mode='lines+markers', connectgaps=True, visible=True, name='Anxiety'), secondary_y=True)\n",
    "fig.add_trace(go.Scatter(x=x, y=fxn_line, mode='lines+markers', connectgaps=True, visible=True, name='Difficulty Functioning'), secondary_y=True)\n",
    "\n",
    "# OPTION 2 = Hometime\n",
    "fig.add_trace(go.Bar(x=x, y=passive_df['hometime'], visible=False, marker=dict(color='#CCCCFF'), name='Hometime'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=x, y=dep_line, mode='lines+markers', connectgaps=True, line=dict(width=2), visible=False, name='Depression'), secondary_y=True)\n",
    "fig.add_trace(go.Scatter(x=x, y=anx_line, mode='lines+markers', connectgaps=True, visible=False, name='Anxiety'), secondary_y=True)\n",
    "fig.add_trace(go.Scatter(x=x, y=fxn_line, mode='lines+markers', connectgaps=True, visible=False, name='Difficulty Functioning'), secondary_y=True)\n",
    "\n",
    "# OPTION 3 = Entropy\n",
    "fig.add_trace(go.Bar(x=x, y=passive_df['entropy'], visible=False, marker=dict(color='#CCFF99'), name='Entropy'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=x, y=dep_line, mode='lines+markers', connectgaps=True, line=dict(width=2), visible=False, name='Depression'), secondary_y=True)\n",
    "fig.add_trace(go.Scatter(x=x, y=anx_line, mode='lines+markers', connectgaps=True, visible=False, name='Anxiety'), secondary_y=True)\n",
    "fig.add_trace(go.Scatter(x=x, y=fxn_line, mode='lines+markers', connectgaps=True, visible=False, name='Difficulty Functioning'), secondary_y=True)\n",
    "\n",
    "# OPTION 4 = Sleep\n",
    "fig.add_trace(go.Bar(x=x, y=sleep_duration, visible=False, marker=dict(color='#FFCC99'), name='Sleep Duration'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=x, y=dep_line, mode='lines+markers', connectgaps=True, line=dict(width=2), visible=False, name='Depression'), secondary_y=True)\n",
    "fig.add_trace(go.Scatter(x=x, y=anx_line, mode='lines+markers', connectgaps=True, visible=False, name='Anxiety'), secondary_y=True)\n",
    "fig.add_trace(go.Scatter(x=x, y=fxn_line, mode='lines+markers', connectgaps=True, visible=False, name='Difficulty Functioning'), secondary_y=True)\n",
    "\n",
    "\n",
    "# OPTION 5 = Nearby Devices\n",
    "try:\n",
    "    ppl = cortex.secondary.nearby_device_count.nearby_device_count(id=part, start=start_date,\n",
    "                                                                    end=end_date, resolution=86400000)['data']\n",
    "    new_dict = {}\n",
    "    for timestamp in ppl['data']:\n",
    "        new_dict[(datetime.fromtimestamp(timestamp['timestamp'] / 1000)).date()] = timestamp['value']\n",
    "        \n",
    "    df = pd.Series(new_dict)\n",
    "    df = pd.DataFrame(df.reset_index())\n",
    "    df.rename(columns={'index': 'timestamp', 0: 'value'}, inplace=True)\n",
    "    \n",
    "    fig.add_trace(go.Bar(x=df['timestamp'], y=df['value'], visible=False, marker=dict(color='#FFCC99'), name='Nearby Devices'), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=x, y=dep_line, mode='lines+markers', connectgaps=True, line=dict(width=2), visible=False, name='Depression'), secondary_y=True)\n",
    "    fig.add_trace(go.Scatter(x=x, y=anx_line, mode='lines+markers', connectgaps=True, visible=False, name='Anxiety'), secondary_y=True)\n",
    "    fig.add_trace(go.Scatter(x=x, y=fxn_line, mode='lines+markers', connectgaps=True, visible=False, name='Difficulty Functioning'), secondary_y=True)\n",
    "\n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type=\"dropdown\",\n",
    "                x=1.3,\n",
    "                y=0.5,\n",
    "                showactive=True,\n",
    "                buttons=list([\n",
    "                    dict(label=\"Screentime\",\n",
    "                         method=\"update\",\n",
    "                         args=[{\"visible\": generate_visibility(0, 5, 4)},\n",
    "                               {\"title\": \"Screentime\"}]),\n",
    "                    dict(label=\"Hometime\",\n",
    "                         method=\"update\",\n",
    "                         args=[{\"visible\": generate_visibility(1, 5, 4)},\n",
    "                               {\"title\": \"Hometime\"}]),\n",
    "                    dict(label=\"Entropy\",\n",
    "                         method=\"update\",\n",
    "                         args=[{\"visible\": generate_visibility(2, 5, 4)},\n",
    "                               {\"title\": \"Entropy\"}]),\n",
    "                    dict(label=\"Sleep Duration\",\n",
    "                         method=\"update\",\n",
    "                         args=[{\"visible\": generate_visibility(3, 5, 4)},\n",
    "                               {\"title\": \"Sleep Duration\"}]),\n",
    "                    dict(label=\"Nearby Devices\",\n",
    "                         method=\"update\",\n",
    "                         args=[{\"visible\": generate_visibility(4, 5, 4)},\n",
    "                               {\"title\": \"Nearby Devices\"}])\n",
    "                ]),\n",
    "            )\n",
    "        ])\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type=\"dropdown\",\n",
    "                x=1.3,\n",
    "                y=0.5,\n",
    "                showactive=True,\n",
    "                buttons=list([\n",
    "                    dict(label=\"Screentime\",\n",
    "                         method=\"update\",\n",
    "                         args=[{\"visible\": generate_visibility(0, 4, 4)},\n",
    "                               {\"title\": \"Screentime\"}]),\n",
    "                    dict(label=\"Hometime\",\n",
    "                         method=\"update\",\n",
    "                         args=[{\"visible\": generate_visibility(1, 4, 4)},\n",
    "                               {\"title\": \"Hometime\"}]),\n",
    "                    dict(label=\"Entropy\",\n",
    "                         method=\"update\",\n",
    "                         args=[{\"visible\": generate_visibility(2, 4, 4)},\n",
    "                               {\"title\": \"Entropy\"}]),\n",
    "                    dict(label=\"Sleep Duration\",\n",
    "                         method=\"update\",\n",
    "                         args=[{\"visible\": generate_visibility(3, 4, 4)},\n",
    "                               {\"title\": \"Sleep Duration\"}])\n",
    "                ]),\n",
    "            )\n",
    "        ])\n",
    "\n",
    "# Set y-axes titles\n",
    "fig.update_yaxes(title_text=\"<b>Survey Score</b>\", secondary_y=True)\n",
    "fig.update_yaxes(title_text=\"<b>Time/Number</b>\", secondary_y=False)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70171a4-1a1a-4f51-92ef-53b5c16dad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_df['depression'] = pd.Series(passive_df['depression']) if isinstance(passive_df['depression'], list) else passive_df['depression']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b5c4bb-ae5a-41ed-ad72-3af3276f400f",
   "metadata": {},
   "source": [
    "#### Steps, shown overlaid with daily anxiety, function, and mood scores. \n",
    "\n",
    "Steps are the number of steps you have taken each day, measured using your phone's accelerometer or health app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa6318-5ad3-4c1a-9896-87f156c1dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    matplotlib.rc_file_defaults()\n",
    "    import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "    ax1 = sns.set_style(style=None, rc=None )\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "    plt.xticks(rotation = 45)\n",
    "\n",
    "\n",
    "\n",
    "    sns.barplot(data = passive_df, x='date', y='steps', alpha=0.5, ax=ax1, color='lightsalmon')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    plt.ylim(0, 10)\n",
    "    sns.lineplot(data = passive_df['anxiety'], marker='o', sort = False, ax=ax2, label='Anxiety', color='blueviolet')\n",
    "    sns.lineplot(data = passive_df['dysfunction'], marker='o', sort = False, ax=ax2, label='Difficulty Functioning', color='firebrick')\n",
    "    sns.lineplot(data = passive_df['depression'], marker='o', sort = False, ax=ax2, label='Depression', color='cornflowerblue')\n",
    "\n",
    "\n",
    "    ax2.set_ylabel('Survey Score')\n",
    "    ax1.set_ylabel('Steps')\n",
    "\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))\n",
    "    \n",
    "    colors = {'Steps':'lightsalmon', 'Anxiety':'blueviolet',\n",
    "         'Difficulty Functioning':'firebrick', 'Depression':'cornflowerblue'}         \n",
    "    labels = list(colors.keys())\n",
    "    handles = [plt.Rectangle((0,0),1,1, color=colors[label]) for label in labels]\n",
    "    plt.legend(handles, labels)\n",
    "except:\n",
    "    print('No step data for this participant. Maybe participant has low data quality or an Android.')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb140417-340d-4a2f-a8bf-5c9d5aaf090d",
   "metadata": {},
   "source": [
    "### Calendar View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f434740-0971-48bc-b957-3ab50f0693dd",
   "metadata": {},
   "source": [
    "These calendars show heatmaps of all of your passive and active variables collected over your time in the clinic. The month is listed on the bottom, the day of the week is shown on the right, and there is a heat map scale on the far right showing the minimum and maximum values for each variable with the corresponding colors. \n",
    "\n",
    "The goal of these graphs is to help pick up on patterns in passive or active data over time, as well as to pick out what days may have been unusual in terms of passive or active data values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257988e-6cde-42d3-942b-16edf9f2f5e5",
   "metadata": {},
   "source": [
    "#### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7543e5b-fb0c-408a-ad87-495e64871b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = passive_df\n",
    "entropy = final_df[['date', 'entropy']]\n",
    "\n",
    "entropy['date'] = pd.to_datetime(entropy['date'], yearfirst=True)\n",
    "entropy.set_index('date', inplace=True)\n",
    "# plot\n",
    "col = 'entropy'\n",
    "calplot.calplot(entropy[col], textfiller='-', dropzero=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64a8af-c47c-4f08-abdd-7a9e672da358",
   "metadata": {},
   "source": [
    "#### Hometime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a06f4-a3e1-49b7-b47f-b3fe93273ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hometime = final_df[['date', 'hometime']]\n",
    "\n",
    "hometime['date'] = pd.to_datetime(hometime['date'], yearfirst=True)\n",
    "hometime.set_index('date', inplace=True)\n",
    "# plot\n",
    "col = 'hometime'\n",
    "calplot.calplot(hometime[col], textfiller='-', dropzero=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb2fba-8304-4610-9527-866290eb76df",
   "metadata": {},
   "source": [
    "#### Data Quality\n",
    "Data quality is an indicator of the quality of your passive (gps, step, etc.) data. On days when you have low data quality, your passive data may not be as accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d58aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b1eda-c3cf-4d59-b596-4440a7ee7371",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quality = final_df[['date', 'data_quality']]\n",
    "\n",
    "\n",
    "data_quality['date'] = pd.to_datetime(data_quality['date'], yearfirst=True)\n",
    "data_quality.set_index('date', inplace=True)\n",
    "# plot\n",
    "col = 'data_quality'\n",
    "calplot.calplot(data_quality[col], textfiller='-', dropzero=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde4c2f5-d3de-4791-979d-d598fdb24792",
   "metadata": {},
   "source": [
    "#### Screen Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3903500a-7d7a-4d1f-86a2-5031e61c336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_duration = final_df[['date', 'screen_duration']]\n",
    "\n",
    "screen_duration['date'] = pd.to_datetime(screen_duration['date'], yearfirst=True)\n",
    "screen_duration.set_index('date', inplace=True)\n",
    "# plot\n",
    "col = 'screen_duration'\n",
    "calplot.calplot(screen_duration[col], textfiller='-', dropzero=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593b60d-bf12-4ec8-8b8c-0b75783f1fde",
   "metadata": {},
   "source": [
    "#### Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2c3e72-ee96-42b8-b2b2-e58f70254cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    steps = final_df[['date', 'steps']]\n",
    "\n",
    "    steps['date'] = pd.to_datetime(steps['date'], yearfirst=True)\n",
    "    steps.set_index('date', inplace=True)\n",
    "    # plot\n",
    "    col = 'steps'\n",
    "    calplot.calplot(steps[col], textfiller='-', dropzero=True);\n",
    "except:\n",
    "    print('No step data for this participant.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5ec317-1534-4694-8dd4-51b2150aa90d",
   "metadata": {},
   "source": [
    "#### Anxiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164bd5c5-eb9b-45bf-98a9-aff628704f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "anxiety = final_df[['date', 'anxiety']]\n",
    "\n",
    "anxiety['date'] = pd.to_datetime(anxiety['date'], yearfirst=True)\n",
    "anxiety.set_index('date', inplace=True)\n",
    "# plot\n",
    "col = 'anxiety'\n",
    "calplot.calplot(anxiety[col], textfiller='-', dropzero=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4d12b-aa34-405a-b544-cf19cd758e66",
   "metadata": {},
   "source": [
    "#### Depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253aa6d-e135-4d66-9790-e8c322a5cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "depression = final_df[['date', 'depression']]\n",
    "\n",
    "depression['date'] = pd.to_datetime(depression['date'], yearfirst=True)\n",
    "depression.set_index('date', inplace=True)\n",
    "# plot\n",
    "col = 'depression'\n",
    "calplot.calplot(depression[col], textfiller='-', dropzero=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfda2b0b-b460-456c-bac2-e6b8255c6896",
   "metadata": {},
   "source": [
    "#### Difficulty Functioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b994d9-a9c1-4748-8c5d-794facd2b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "dysfunction = final_df[['date', 'dysfunction']]\n",
    "\n",
    "dysfunction['date'] = pd.to_datetime(dysfunction['date'], yearfirst=True)\n",
    "dysfunction.set_index('date', inplace=True)\n",
    "# plot\n",
    "col = 'dysfunction'\n",
    "calplot.calplot(dysfunction[col], textfiller='-', dropzero=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8520fae0-cef3-4d9d-86fd-4ae14225b2ce",
   "metadata": {},
   "source": [
    "#### Sleep Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ec576-531a-426a-944c-445020f822f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sleep_duration_hours' in final_df.columns:\n",
    "    sleeptime = final_df[['date', 'sleep_duration_hours']]\n",
    "    sleeptime['date'] = pd.to_datetime(sleeptime['date'], yearfirst=True)\n",
    "    sleeptime.set_index('date', inplace=True)\n",
    "    col = 'sleep_duration_hours'\n",
    "    calplot.calplot(sleeptime[col], textfiller='-', dropzero=True)\n",
    "else:\n",
    "    print(\"No Daily Sleep Surveys found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf160c-6a48-4ba0-a184-39a11a4b920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qual=cortex.secondary.data_quality.data_quality(id=part, start=cortex.now()-7*MS_IN_DAY, \n",
    "                                                     end=cortex.now(), resolution=86400000, \n",
    "                                                     feature='accelerometer', bin_size=10000)['data']\n",
    "#dq of the last week~! \n",
    "import plotly.graph_objects as go\n",
    "last_week=data_qual[-7:]\n",
    "dq=[day['value'] for day in last_week]\n",
    "avg_dq=sum(dq)/7\n",
    "fig = go.Figure(go.Indicator(\n",
    "    domain = {'x': [0, 1], 'y': [0, 1]},\n",
    "    value = avg_dq,\n",
    "    # mode = \"gauge+number+delta\",\n",
    "    mode='gauge+number',\n",
    "    title = {'text': \"Average Data Quality in the Past Week\"},\n",
    "    delta = {'reference': .44},\n",
    "    gauge = {'axis': {'range': [None, 1]},\n",
    "             'bar': {'color': \"black\", 'line': {'color':'red', 'width':0}, 'thickness': .1},\n",
    "             'shape': 'angular',\n",
    "             'steps' : [\n",
    "                 {'range': [0, .35], 'color': \"#E74C3C\"},\n",
    "                 {'range': [.35, .6], 'color': \"#F4D03F\"},\n",
    "                 {'range': [.6, .8], 'color': \"#27AE60\"},\n",
    "                 {'range': [.8, 1], 'color': \"#2471A3\"}]}))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de52fb18-99a1-46c8-9c60-77e3ddcbef52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook TMLDNreport.ipynb to html\n",
      "[NbConvertApp] Writing 294763 bytes to reports/TMLDNreport.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html --TemplateExporter.exclude_input=True TMLDNreport.ipynb --output-dir=./reports --output=TMLDNreport.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e1a13-f8ff-4e53-abb9-2b580b7af286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "cortex.visualizations.participant.active(part, attach_graphs=True)\n",
    "cortex.visualizations.participant.passive(part,attach_graphs=True)    \n",
    "cortex.visualizations.participant.cortex_tertiles(part,attach_graphs=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
